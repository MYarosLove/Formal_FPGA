G-QED: Generalized QED Pre-silicon Verification beyond Non-Interfering Hardware Accelerators

Abstract—Hardware accelerators (HAs) underpin high- performance and energy-efficient digital systems. Correctness of these systems thus depends on the correctness of constituent HAs. Self-consistency-based pre-silicon verification techniques, like A-QED (Accelerator Quick Error Detection), provide a quick and provably thorough HA verification framework that does not require extensive design-specific properties or a full functional specification. However, A-QED is limited to verifying HAs which are non-interfering — i.e., they produce the same result for a given input independent of its context within a sequence of inputs. We present a new technique called G-QED (Generalized QED) which goes beyond non-interfering HAs while retaining A-QED’s benefits. Our extensive results as well as a detailed industrial case study show that: G-QED is highly thorough in detecting critical bugs in well-verified designs that otherwise escape traditional verification flows while simultaneously improving verification productivity 18-fold (from 370 person days to 21 person days). These results are backed by theoretical guarantees of soundness and completeness.

Index Terms—QED, Quick Error Detection, Accelerators, Processors, Functional consistency

I. INTRODUCTION
Domain-specific hardware accelerators (HAs) are becoming increasingly crucial for high-throughput and energy-efficient digital systems. Today’s digital systems, often referred to as System-on-Chips or SoCs, contain many HAs spanning various application domains. Each HA implements a set of functions referred to as Actions in this paper. HAs may be tightly-coupled, e.g., integrated within a processor’s pipeline. More commonly though, HAs are loosely-coupled, interacting with other SoC components (other HAs, processor cores, memory) via on-chip networks. Given their pervasiveness [1], [2], loosely-coupled HAs (LCAs) are the focus of this paper although our presented techniques can be applied to tightly- coupled HAs as well.
Every HA must be verified for correctness both thoroughly and quickly to meet the time-to-market demands of the diverse applications they support [3]. As discussed in many prior publications [4]-[7], HA formal verification is challenged by: (1) the tremendous effort required to craft highly thorough design-specific properties and full functional specifications, and (2) the scalability of off-the-shelf formal tools. Beyond being time-consuming and error prone [4], [5], producing thorough properties and specifications is an uphill battle due to the rapidly evolving nature of HAs that support rapidly evolving applications.
A recent verification technique, Accelerator Quick Error Detection (A-QED, [6], [7]), overcomes the above challenges for a class of HAs that are non-interfering — i.e., HAs that produce the same output for a given action independent of its context within a sequence of actions. A-QED uses formal verification based on Bounded Model Checking (BMC, [8]). Unlike conventional BMC-based verification, A-QED does not
require extensive design-specific properties or a full functional specification. Instead, A-QED uses self-consistency checks on a given HA. Specifically, A-QED checks for functional consistency (FC), the property that actions with identical inputs always produce the same outputs. In addition to FC, A-QED also performs single-action checking (SAC) and response bound checking (RB) explained later in this paper. A-QED is
sound and complete for non-interfering HAs.
While non-interfering HAs readily capture a range of fixed- function designs, interfering HAs are becoming more and more prevalent. This is partly due to the rise of programmable HAs [9]. In fact, traditional processors may be viewed as an extreme case of interfering HAs where each instruction is an HA action. Interfering HAs contain interfering actions whose outputs are dependent on the outputs of other actions, inherently violating A-QED’s FC checking. To complicate matters even further, an HA action might read the outputs produced by another action (or write its outputs to be con- sumed by another action) at clock cycles that depend on the execution of various other concurrent actions active in the HA. Thus, there is an urgent need for a new and general formal verification methodology for interfering (and non-interfering) HAs that preserves the benefits of A-QED (ie., provably sound and complete verification without requiring extensive design-specific properties or full functional specifications) while reasoning about interfering actions (not possible using A-QED) - a highly difficult challenge.
In this paper, we overcome this challenge through G-QED or Generalized QED — a new technique for thoroughly verifying both interfering and non-interfering HAs (and processor cores by extension) — and make the following contributions:

«Given an HA with its set of actions, we present the G- QED technique to thoroughly verify that HA without requiring detailed knowledge about its design or the interfering nature of its various actions. G-QED supports both RTL and high-level synthesis design flows and integrates seamlessly with several industrial BMC tools. e 
We provide a formal model of HAs, demonstrate its broad applicability, and prove soundness and complete- ness guarantees of G-QED for such HAs. 
We demonstrate the effectiveness and practicality of G-QED through extensive results on a wide variety of 44 moderate-sized HAs and processor cores (that fit in existing BMC tools).
We present an industrial case study on live designs and demonstrate: (1) Significantly improved bug coverage of G-QED by uniquely detecting corner-case bugs that escaped industrial (simulation- and formal verification- based) verification flow (in addition to detecting all bugs detected by the industrial flow). (2) Dramatically improved verification productivity of G-QED, from 370 person days using industrial flow to only 21 person days using G-QED - an 18-fold boost. (3) G-QED- enabled short design-design verification loops with quick turnaround for rapidly evolving designs.

While we focus on moderate-sized HAs that fit in existing BMC tools, there are further scale up opportunities, e.g., new decomposition techniques enabled by self-consistency checking [7] — a topic of future work.

II. MOTIVATING EXAMPLE
The representative HA in Fig. 1 (adapted from a commercial design) is used to illustrate interfering HA verification challenges. The HA is connected to other SoC components via a handshake protocol similar to [6]. The HA only reads valid inputs (in_valid asserted) from the network when it is ready (rdy_our asserted). The network reads HA-generated outputs (out_valid asserted) when it is not blocked by other components (rdy_in asserted). The HA implements 3 actions {A1, Az, As} as follows:
A1(D): updates Bypass register with D.
A2(D): updates Factor register with D. Az is stored in FIFO 2.
A3(D, Bypass, Factor): generates an output O = F(D) scaled by the factor register value. The scaling operation is skipped depending on the Bypass register’s value. A3 is stored in FIFO 1. The output of this interfering action depends not only on D, but also on the values of the Factor and Bypass registers. The Bypass and Factor registers constitute the Relevant State Registers (RSRs) of A3. RSRs are formally defined in 
Sec. IV
F() and Scaler() take multiple cycles to compute and pending inputs are stored in the FIFOs. If either FIFO is full, the HA switches to fast F() implementation. If any of the Scaler() inputs is 0, the unit is designed to skip computation for better power and performance. Thus, when the Scaler() unit is bypassed, the HA updates F'actor register with 0.
Consider the following bug (adapted from an actual bug) - the FIFO I full signal goes high only when the write pointer reaches 15 (starting from 0) but the FIFO can hold at most 15 entries. Hence, the 16** A3 overwrites its predecessor. This bug is only triggered if the rdy_in is low long enough. It can be detected by checking A3 for FC. However, to perform FC, we need to constrain the RSRs to prevent false fails.

Challenge 1: The exact clock cycles when RSRs are read depend on the internal state and can be different for different RSRs. For example, consider action A3. When the result of F'() is fed to the Scaler(), the value stored in Factor is also read. It is very important to precisely specify the clock cycle during which this value should be read. That is not an easy task because it depends on the latency of F'() (which in turn depends on the FIFO 1 state). Incorrect timing information can result in false fails.
Challenge 2: Consider the same bug in FIFO 2. If we constrain Factor to a fixed value, As will always read the same value from the Factor register and pass FC check.
Challenge 3: Checking FC on A2 is a non-trivial problem since an update can happen either from A2 or because the HA updates it to 0 when the Scaler() is bypassed. So it is not necessary that the 2°” input will produce the i*” update to the Factor register. Thus, we need to understand the design implementation to figure out when an input updates the register.

III. G-QED
The new FC approach is shown in Fig. 2. To check FC for the action pair {a,b}, the BMC runs three copies of the HA from the reset state. The same input sequence I0 ... Ik; is fed to the first two copies. For the first copy, the HA is allowed to finish executing all the inputs and then the RSRs for actions a and b are saved. For the second copy, input pair Ia, Ib corresponding to the action pair {a,b} is fed to the HA and the output pair {Oa, Ob} is recorded. For the third copy, an input sequence Im+1 In, which is not necessarily the same as I0 ... Ik, is allowed to finish executing before sending the input pair I0 ... Ik to the HA. The RSRs are saved before sending Ia, Ib and constrained to be the same as the RSR values saved in the first copy. Additionally, the output pair {Oa, Ob} is checked with that from the second copy. The FC property is formulated as:
We assume that they RSRs used to calculate {Oa, Ob} in the second copy have the same values as those saved in the first copy. This is elucidated in the following design constraint: 
Design Constraint: If we send the input pair {Ia, Ib} after all the inputs have finished executing in the first copy, then the output pair generated is the same as {Oa, Ob} in the second copy.
This means the output generated or the RSR updated by an action in a sequence is independent of how long the design is idle in between the inputs. The HA example in Sec. II is idling when the in_valid is low. During this time, no more inputs are accepted by the HA but previous inputs keep executing. We have seen this constraint to hold for all the designs we looked at in Sec. V. We avoid the Challenges I and 2 by constraining RSRs when no inputs are being executed.
In case of challenge 3, the Factor value updated by A2 can be propagated as an output of a future Az action. Thus, we address challenge 3 by FC for the action pair {A2, A3} instead of checking FC for A2 action.

Pair wise checking of actions allows us to find bugs in the RSR updating logic since checking the RSRs directly is non- trivial for a general HA as discussed in Challenge 3 in Sec. IL. However, this is not the case for processors, so we consider all the RSRs as the output of every instruction. Thus, we don’t have to check instructions in pairs for processors. 
To catch the FIFO 2 bug, BMC will run:
In the first copy, an input sequence such that 14 FIFO entries are filled. It will collect the RSRs after the input sequence has finished executing.

In the second copy the same sequence followed by Ia2 Ia3, and Ia2. Because of the bug, Ia2 will be overwritten and output will be F(Ia3) * Ia2
In the third copy an input sequence such that the RSR values after it finishes execution, the RSRs values match that of the first copy. Next, the BMC sends Ia2, Ia3, and the output will be F(I4,) x Ij2 not equal to the output
in second copy.
The bug in FIFO 1 can be caught in a similar manner.
To ensure completeness, we run RB as well as SAC [6]. RB checks that the output for an input in a sequence is generated within some time bound. It works for interfering HAs. To check SAC for interfering actions, we need to consider the RSR values. To perform SAC on the action pair {A1, A2}, starting from reset state, we check that for all valid input values and associated RSRs the output produced by the HA is the same as expected by the A, and Ap actions.

IV. FORMAL MODELS AND THEORETICAL RESULTS
In this section, we formalize G-QED. We adapt the HA formalism from [6] to model a general set of HAs. Such transition systems implicitly include a clock signal to synchronize transitions between system states [10]. Additionally, we formally define the notion of RSRs, the total correctness of the HA in the context of RSRs, and the FC property. We prove that FC is both sound and complete.

We first simplify the HA model in [6] by modeling all redundant inputs (either because the HA is not ready to read or the input is invalid) as an invalid action a, (the two cases of redundancy were handled separately in [6]). We similarly model redundant outputs (invalid or the host is not ready to read the output) as 0, . To model actions that only update RSRs and do not produce any output, we distinguish A,. from the full set of actions A. The actions that update the Bypass and Factor registers in Fig. 1 belong to this class of actions.

... 
V. RESULTS

A. G-QED for Various HAs and Processor Cores
We demonstrate the effectiveness and practicality of GCQED using 44 designs covering a wide variety of HAs and processor cores, including several industrial designs. While we focus on interfering HAs, we have also included non-interfering HAs to demonstrate the generality of G-QED. The HAs represent diverse application domains such as security, neural nets, and image processing. The processor cores belong to the RISC- V family [11] targeting embedded security and automotive domains. The design sizes are suitable for existing BMC tools.
Table I summarizes the results. All designs were previously verified using state-of-the-art simulation-based verification. The industrial designs were additionally verified using state- of-the-art formal verification. All designs were available in Verilog RTL. For G-QED runs on Open Source Designs, we used JasperGold® (V2016.09p002) on an Intel®Xeon® ES- 2640 v3 with 128GB of DRAM. We used OneSpin 360 DV-Verify®on an Intel®Xeon®E5-2690 v3@2.6GHz with 50GB RAM to run G-QED on Industrial Designs.

Observation 1: G-QED enables highly thorough verification of a wide variety of HAs and processor cores. G-QED uniquely detected bugs that were missed by conventional verification flows (which includes both simulation and traditional formal verification), in addition to all bugs detected using those flows. The bugs uniquely detected by G-QED represent corner-case scenarios that are often highly difficult to detect. For example, for the AIE-A design, G-QED detected a difficult bug which got triggered by a complex sequence of 16 actions causing some inputs of another action to be dropped. G-QED could detect this bug within 5 hours with a 32-cycle counterexample. From our industrial experience, such bugs can be very tricky to detect using simulations.

Observation 2: G-QED enables quick verification of HAs and processors. G-QED detected bugs quickly with short counterexamples (in terms of clock cycles), which in turn enabled quick debug. Since G-QED uses BMC, it finds the shortest sequence to detect bugs. This is in sharp contrast to conventional flows where counterexample lengths and error traces are highly dependent on the precision of properties, assertions, and test cases. The effort required to set up G-QED is small resulting in large verification productivity benefits — an apples-to-apples comparison with industrial verification flows is presented in Sec. V-B.

Observation 3: G-QED provides a unified verification solution for interfering HAs, non-interfering HAs, and processor cores. G-QED thus advances state-of-the-art compared to other QED pre-silicon verification techniques such as A- QED [6] (for non-interfering HAs), and Symbolic QED [12], S?QED [13], and C-S2QED [14] (for processor cores).
Observation 4: G-QED integrates seamlessly with various BMC engines. We used G-QED together with Jasper- Gold® (V2016.09p002) from Cadence and OneSpin 360 DV- Verify® from Siemens EDA to generate Table I. B. Industrial Case Study on Live Designs
For an apples-to-apples comparison of G-QED versus industrial verification flows, we conducted a case study using Artificial Intelligence Engine (AJE) HAs. We had access to several (buggy) versions of two Verilog designs, AIE-A and AIE-D (Table I, where AIE-D is a derivative of AIE-A with additional features. Both designs represent interfering HAs that are also LCAs. At the start of our G-QED study, both HAs already passed pre-silicon verification sign-off and were in the final stages of design — hence, we refer to them as dive designs.

1) Industrial Verification Flow: Our industrial verification flow included both Constrained Random Simulation (CRS) with UVM-based [15] test bench and Formal Verification (FV) with design-specific properties. CRS was carried out at the top level, targeting all design functionality. For design- specific property creation, a framework similar to [16]. was used to reduce manual effort. A standard industrial verification process similar to [17] was employed. The sign-off criteria for verification was 100% structural code coverage and 100% functional coverage from both CRS and FV combined.
2) G-QED Flow: For each AIE HA, we defined the set of actions and extracted the associated RSR registers and input- output interface protocol details with help from design engineers. We then used the methodology explained in Sec. III. No knowledge of the internal architecture (performance optimizations, parallelism, internal pipelining) or existing industrial verification flow was required. With the G-QED FC (Sec. IID, we were able to detect and root-cause 9 new bugs (missed by the industrial flow) within 3 person weeks, in addition to detecting bugs detected by the industrial flow (Table II).

Observation 5: G-QED significantly improves bug coverage versus industrial verification flows. G-QED uniquely detected 9 corner-case and difficult-to-activate bugs in well- verified industrial designs. Of these 9 bugs, 4 were due to the specification inaccuracies and 5 were in the RTL implementations that were only triggered by a complex sequence of actions. All these bugs were detected in less than 5 hours.

Observation 6: G-QED dramatically improves verification productivity. The industrial verification flow required 370 person days for the two HAs. G-QED required only 21 person days (including setup, running the BMC tool, and root-cause analysis) — an 18-fold verification productivity boost.

Observation 7: G-QED can be set up very quickly. It took only 7 and 2 person days for AIE-A and AIE-D to set up G-QED, respectively. In contrast, industrial verification flows often require detailed information about a design and its implementation. For the AIE HAs, it took 250 person days to set up CRS and FV (test bench and property development).

Observation 8: G-QED enables quick debug. G-QED produced short counter-examples (32 cycles or fewer) for the AIE HAs (Table I) resulting in quick debug (less than a day). cause analysis. G-QED effort in Table II includes this debug effort. In contrast, it took several days for root cause analysis of some of the bugs detected by CRS.

Observation 9: G-QED does not require low-level design details. G-QED largely relies on self-consistency checks, minimizing the need to understand deep design details. This saves verification effort significantly.

Observation 10: G-QED enables short design-design verification loops with quick turnaround for rapidly evolving designs. Once the bugs detected by G-QED were fixed, we could reuse G-QED immediately to verify the fixed designs with little or no additional effort. In contrast, it required up to 120 person days for CRS and FV to debug, fix, update test cases and properties, and rerun verification.

VI. RELATED WORK
Simulation-based methodologies dominate the pre-silicon verification practice in industry [15], [17], [18]. However, as demonstrated in Sec. V-B, simulation-based methods are inadequate for ensuring thorough and quick verification of HAs. While simulation scales for large designs, there can be major scale up opportunities for G-QED using techniques such as [7] — a topic of future work.
While G-QED employs BMC for self-consistency checking, it differs from traditional formal verification (Sec. V-B). G- QED can leverage recent formal verification advances to further reduce associated manual efforts (e.g., automatic RSR extraction [19], ILA [5]).
Self-consistency-based checking has its roots in fault-tolerant computing, including the use of design diversity. For pre-silicon verification, publications such as [20], [21] are relevant. Completeness guarantees may be affected by these techniques (e.g., for a bug always triggered by a particular sequence of instructions, irrespective of the number of NOPs and stalls inserted in the sequence). Another closely approach [22] requires specific clock cycles when RSRs are read and written, which can be very challenging for HAs (Sec. ID). In contrast, we proved G-QED to be sound and complete.

TABLE IL. G-QED VS. OTHER PRE-SILICON QED TECHNIQUES

Recently, there have been several publications on various flavors of QED pre-silicon verification techniques, namely, Symbolic QED [12], S?QED [13], C-S2QED [14], A-QED [6], and A-QED? [7]. Table III contrasts these techniques versus G-QED with respect to various attributes.

VII. CONCLUSION
G-QED presents a unified approach to highly thorough pre-silicon verification of interfering HAs, non-interfering HAs, and processor cores through self-consistency. With modest design assumptions, G-QED has been proven to be sound and complete. Results from a wide variety of designs, including an industrial case study, demonstrate its effectiveness and practicality. G-QED creates several promising research directions: (1) scale-up to very large designs through new decomposition and abstraction techniques (e.g., [7]). (2) G-QED with symbolic starting states to overcome BMC bounds; (3) G-QED for verifying third-party IP blocks with little/obfuscated internal design details; (4) functional safety verification through a combination of G-QED and formal fault injection techniques; and, (5) G-QED for deriving side-channel attacks in HAs (similar to timing side channels for processors [24]).

ACKNOWLEDGEMENT 
This work was supported in part by ACE (one of the seven centers in JUMP 2.0, a Semiconductor Research Corporation (SRC) program sponsored by DARPA), Stanford SystemX Alliance, and SRC-sponsored Global Research Collaboration.